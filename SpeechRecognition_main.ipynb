{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition using Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team members: Adrian Löwenstein, Kiran Bacsa, Manuel Vonlanthen<br>\n",
    "Date:         22.01.2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will describe in detail the problem we studied during the final project of the course \"Network Tour of Data Science\". We wanted to do speech recognition using the Graph/Network theory learned during the course. We were inspired by the kaggle competition \"Tensor Flow Speech Recognition Challenge: Can you build an algorithm that understands simple speech commands\" put up by google. In said competition the goal was to classify 20 distinct words. Words that do not belong to any of the 20 classes should be classified as \"unknown\". For the kaggle competition the TensorFlow library had to be used. For this purpose Google provided a large training data set (64'720 audio files) with known labels and an even larger test (150'000+ audio files) with unknown labels for them to evaluate the built algorithms. We, however, decided to only work with the provided training data, because the data set is large enough to perform statistically valid model evaluation and it this we we weren't dependant on the kaggle competition.<br>\n",
    "<br>\n",
    "The provided data set consists of 64'720 .wave files of length 1s, sampled with a sampling rate of $16$ kHz. Each audio files contain one of 30 possible spoken words. The files were created using crowd-sourcing, which means that the conditioning of the audio signal is not equal for all audio files. This led to very different noise levels, amplitudes, etc. Also the same speaker might have recorded different audio files. The 20 core words which have to be classified correctly are:\n",
    "\n",
    "    - up, down\n",
    "    - zero, one, two, three, four, five ,six ,seven, eight, nine\n",
    "    - go, stop \n",
    "    - left, rigth\n",
    "    - no, yes\n",
    "    - off, on\n",
    "In addition to these 20 words, 10 other words were provided inside the training set to train the algorithm to classify words which it should not react to as \"unknown\". The following \"unknown\" words are contained in the training data:\n",
    "\n",
    "    - bed\n",
    "    - bird, cat, dog, mouse\n",
    "    - tree\n",
    "    - happy\n",
    "    - marvin, sheila\n",
    "    - wow\n",
    "<br>\n",
    "At this point we want to empphasize that we did not study the problem suggested for the kaggle competition, but a slightly simplified one. First of all we did not restrict ourselves to using TensorFlow, in fact we did not use it at all. However, we did restrict ourselves to use Graph theory as central part of our classification algorithm. Our goal was, using only the provided training set, to build a classifier which calssifies the above listed core words as accurate as possible. In addition, all other words (the 10 additional words) should be classified as \"unknown\". This means we wanted to build a \"word\"-classifier for 21 different classes using graph theory.<br>\n",
    "<br>\n",
    "Mathematically, we can define the task as follows. We split up our training data set into a training set $S_t$ of some size N (we will later comment on its size) and a validation set $S_v$ of size $V = 64'720-N$, used to check how well the classifier works.\n",
    "Using $\\mathbf{x_n} \\in S_t$, which is some training audio file $\\mathbf{x_n} \\in \\mathbb{R}^D$, where $D = 1s\\cdot 16kHz = 16000$ is the number of samples per audio file, we can build our training data matrix $\\mathbf{X}^{\\mathbf{N\\times D}}$. Using $\\mathbf{X}$ we want to learn a function $f(\\mathbf{v_v}, \\mathbf{X}): \\mathbb{R}^{N+1\\times D} \\to \\{1,2,3,...,21\\}$, where $\\mathbf{v_v}\\in S_v$ is a validation audio file $\\mathbf{v_v}\\in\\mathbb{R}^D$, such that the resulting estimated label $\\hat{y_v} = f(\\mathbf{v_V}, \\mathbf{X})$ is equal to the correct label $y_v \\in \\{1,2,3,...,21\\}$ for as many validation samples as possible. Hence we use the accuracy measure defined as\n",
    "$$acc = \\frac{\\sum_{i=1}^{K}\\max[\\min[(|y_k-\\hat{y_k}|),1],0]}{K},$$\n",
    "where $K$ is the number of tested samples $v_k$. We want to remark that the model could also work with a subset $\\mathbb{v}\\subseteq S_v$, also called batch, instead of a single validation file $v_v$. In this case we define the cardinality of said subset $|\\mathbb{v}|=K$ and the model would correspond to $f(\\mathbb{v}, \\mathbf{X}): \\mathbb{R}^{(N+K)\\times D} \\to \\{1,2,3,...,21\\}^K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy import sparse, stats, spatial\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "\n",
    "# Benchmarking\n",
    "import time\n",
    "\n",
    "# Cutting \n",
    "\n",
    "from cut_audio import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** If you set recompute to True this will reextract all featrues and re-classify all audio file, which will take several days, so do not do it. It is here for completeness so you can see how the steps were done during th project. We've already computed these steps and saved the results into pickle files. Our entire used data, as well as the pickle files can be found on \"Link\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recompute = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction (Adrian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the data set....<br>\n",
    "Describe the entire pipeline from audio file to feature vector for one audio dile...<br>\n",
    "Shortly mentione other Features that were tried...<br>\n",
    "Set up python function in which the features of the entire training set could be extracted and put it into a if recompute is true... <br>\n",
    "Load the pickle with all features in them,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">info</th>\n",
       "      <th colspan=\"17\" halign=\"left\">mfcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word</th>\n",
       "      <th colspan=\"17\" halign=\"left\">raw_mfcc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../Project/data/train/audio/bed/988e2f9a_nohas...</td>\n",
       "      <td>988e2f9a</td>\n",
       "      <td>bed</td>\n",
       "      <td>-532.804</td>\n",
       "      <td>-373.747</td>\n",
       "      <td>-281.723</td>\n",
       "      <td>-259.193</td>\n",
       "      <td>-260.494</td>\n",
       "      <td>-258.983</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9078</td>\n",
       "      <td>-6.68038</td>\n",
       "      <td>-12.3779</td>\n",
       "      <td>-7.88019</td>\n",
       "      <td>-4.89838</td>\n",
       "      <td>5.09246</td>\n",
       "      <td>5.23662</td>\n",
       "      <td>5.81571</td>\n",
       "      <td>2.533</td>\n",
       "      <td>3.65357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>../Project/data/train/audio/bed/6d818f6c_nohas...</td>\n",
       "      <td>6d818f6c</td>\n",
       "      <td>bed</td>\n",
       "      <td>-407.218</td>\n",
       "      <td>-255.981</td>\n",
       "      <td>-163.47</td>\n",
       "      <td>-131.31</td>\n",
       "      <td>-112.495</td>\n",
       "      <td>-118.76</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523793</td>\n",
       "      <td>-2.98547</td>\n",
       "      <td>-3.1049</td>\n",
       "      <td>-10.3242</td>\n",
       "      <td>-19.2463</td>\n",
       "      <td>-25.6867</td>\n",
       "      <td>-23.1932</td>\n",
       "      <td>-13.7993</td>\n",
       "      <td>-17.9949</td>\n",
       "      <td>-12.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>../Project/data/train/audio/bed/93ec8b84_nohas...</td>\n",
       "      <td>93ec8b84</td>\n",
       "      <td>bed</td>\n",
       "      <td>-466.171</td>\n",
       "      <td>-337.843</td>\n",
       "      <td>-244.057</td>\n",
       "      <td>-223.569</td>\n",
       "      <td>-248.308</td>\n",
       "      <td>-250.754</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.4222</td>\n",
       "      <td>-8.93999</td>\n",
       "      <td>-2.63587</td>\n",
       "      <td>-2.76918</td>\n",
       "      <td>-9.29244</td>\n",
       "      <td>-14.9003</td>\n",
       "      <td>-17.6517</td>\n",
       "      <td>-15.8084</td>\n",
       "      <td>-25.7532</td>\n",
       "      <td>-30.9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>../Project/data/train/audio/bed/a9abc695_nohas...</td>\n",
       "      <td>a9abc695</td>\n",
       "      <td>bed</td>\n",
       "      <td>-556.172</td>\n",
       "      <td>-371.435</td>\n",
       "      <td>-267.924</td>\n",
       "      <td>-229.983</td>\n",
       "      <td>-221.044</td>\n",
       "      <td>-213.585</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.8834</td>\n",
       "      <td>-18.6183</td>\n",
       "      <td>-15.9497</td>\n",
       "      <td>-13.2618</td>\n",
       "      <td>-9.06467</td>\n",
       "      <td>-12.7498</td>\n",
       "      <td>-12.3417</td>\n",
       "      <td>-14.7705</td>\n",
       "      <td>-19.5946</td>\n",
       "      <td>-22.2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>../Project/data/train/audio/bed/a8cb6dda_nohas...</td>\n",
       "      <td>a8cb6dda</td>\n",
       "      <td>bed</td>\n",
       "      <td>-483.963</td>\n",
       "      <td>-384.623</td>\n",
       "      <td>-221.676</td>\n",
       "      <td>-136.899</td>\n",
       "      <td>-108.406</td>\n",
       "      <td>-110.998</td>\n",
       "      <td>...</td>\n",
       "      <td>9.02163</td>\n",
       "      <td>2.85084</td>\n",
       "      <td>-1.81553</td>\n",
       "      <td>-2.05279</td>\n",
       "      <td>0.79797</td>\n",
       "      <td>-2.28227</td>\n",
       "      <td>-10.0107</td>\n",
       "      <td>-13.8224</td>\n",
       "      <td>-10.9754</td>\n",
       "      <td>-9.73626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       info                                                                    \\\n",
       "  iteration                                               path   speaker word   \n",
       "                                                                                \n",
       "0         0  ../Project/data/train/audio/bed/988e2f9a_nohas...  988e2f9a  bed   \n",
       "1         2  ../Project/data/train/audio/bed/6d818f6c_nohas...  6d818f6c  bed   \n",
       "2         0  ../Project/data/train/audio/bed/93ec8b84_nohas...  93ec8b84  bed   \n",
       "3         1  ../Project/data/train/audio/bed/a9abc695_nohas...  a9abc695  bed   \n",
       "4         0  ../Project/data/train/audio/bed/a8cb6dda_nohas...  a8cb6dda  bed   \n",
       "\n",
       "      mfcc                                                ...               \\\n",
       "  raw_mfcc                                                ...                \n",
       "         0        1        2        3        4        5   ...          190   \n",
       "0 -532.804 -373.747 -281.723 -259.193 -260.494 -258.983   ...       1.9078   \n",
       "1 -407.218 -255.981  -163.47  -131.31 -112.495  -118.76   ...    -0.523793   \n",
       "2 -466.171 -337.843 -244.057 -223.569 -248.308 -250.754   ...     -19.4222   \n",
       "3 -556.172 -371.435 -267.924 -229.983 -221.044 -213.585   ...     -13.8834   \n",
       "4 -483.963 -384.623 -221.676 -136.899 -108.406 -110.998   ...      9.02163   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "       191      192      193      194      195      196      197      198   \n",
       "0 -6.68038 -12.3779 -7.88019 -4.89838  5.09246  5.23662  5.81571    2.533   \n",
       "1 -2.98547  -3.1049 -10.3242 -19.2463 -25.6867 -23.1932 -13.7993 -17.9949   \n",
       "2 -8.93999 -2.63587 -2.76918 -9.29244 -14.9003 -17.6517 -15.8084 -25.7532   \n",
       "3 -18.6183 -15.9497 -13.2618 -9.06467 -12.7498 -12.3417 -14.7705 -19.5946   \n",
       "4  2.85084 -1.81553 -2.05279  0.79797 -2.28227 -10.0107 -13.8224 -10.9754   \n",
       "\n",
       "            \n",
       "            \n",
       "       199  \n",
       "0  3.65357  \n",
       "1   -12.81  \n",
       "2 -30.9885  \n",
       "3 -22.2862  \n",
       "4 -9.73626  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load features\n",
    "features_og = pd.read_pickle('./Features Data/cut_mfccs_all_raw_10_1028_20.pickle')\n",
    "features_og.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Classification (Manuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted some meaningful features from the raw data, we want to build a model that uses some training set $S_t$ of cardinality $|S_t|=N$, which can be used to classify the rest of the data (validation set). Our best classification was achived using multi-class semi-supervised classification on graphs, which we'll describe in this section.<br>\n",
    "<br>\n",
    "We found that using a training set of cardinality $|S_t| = N = 4800$ and a validation batch size of $|\\mathbb{v}|= K = 200$ to be both computationally reasonable and yielding good results. This means that we use the same $N$ datapoints (feature vectors of audio files), of which we know the labels, to classify all other audio files (validation set), of which we pretend not to know the labels. The classification of the validation set (size 64'720) is done batch-wise, i.e. $K$ files are classified simultaniously and we iterate trough the entire validation set. Which $N$ datapoints are chosen to form the training set is determined randomly with a restriction that every word (or class) is represented equally. Thus, for $N = 4800$ we choose $160$ audio samples of every one of the 30 clases/words at random.<br>\n",
    "<br>\n",
    "In this section we will classify one batch of size $K = 200$ and while doing that explain the method of semi-supervised classification using graphs in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step, we create the label vector $\\mathbf{y}\\in\\{1,2,3,...,21\\}^{64'720}$ for all datapoints. In addition we plot the labels and the distribution of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 64720 datapoints over the entire dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'number of datapoints')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAFBCAYAAADkL4XrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20459a25d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Label vector\n",
    "# Define class name vector, the index will correspond to the class label\n",
    "class_names = features_og['info']['word'].unique()\n",
    "y = np.ones(len(features_og))\n",
    "for i in range(0,len(class_names)):\n",
    "    y +=(features_og['info','word'] == class_names[i]) * i\n",
    "    \n",
    "# Plot the label vector\n",
    "print('We have {} datapoints over the entire dataset.'.format(len(y)))\n",
    "fix, axes = plt.subplots(1, 2, figsize=(17, 5))\n",
    "axes[0].plot(y)\n",
    "axes[0].grid()\n",
    "axes[0].set_xlabel('datapoint n')\n",
    "axes[0].set_ylabel('label yn')\n",
    "\n",
    "\n",
    "# Plot distribution of classe\n",
    "axes[1].hist(y,30)\n",
    "axes[1].set_xlabel('class')\n",
    "axes[1].set_ylabel('number of datapoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: The classes are not perfectly balanced between classes since $64'720/30 = 2157.33$. However, the set is almost balanced between the 30 classes as we can see in the plot above, which is good enough for our application. In a next step, we split the dataset into a training set $S_t$ of size $N=4800$ and a validation set, as described above. We specify how many datapoints per class are sampled at random to build the training and the validation set respectively. We choose 160 samples for the training set ($30*160 = 4800$) and 1997 samples for the validation set ($1997*30 = 59910$). The remaining 10 words are being discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2157"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "160+1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1713\n",
      "1730\n",
      "1733\n",
      "1746\n",
      "2359\n",
      "2352\n",
      "2357\n",
      "2372\n",
      "2372\n",
      "1742\n",
      "1750\n",
      "2353\n",
      "1746\n",
      "2364\n",
      "2375\n",
      "2357\n",
      "2367\n",
      "2370\n",
      "2367\n",
      "2377\n",
      "1734\n",
      "2369\n",
      "2380\n",
      "2356\n",
      "1733\n",
      "2373\n",
      "2375\n",
      "1745\n",
      "2377\n",
      "2376\n"
     ]
    }
   ],
   "source": [
    "for i in range(31):\n",
    "    print(np.sum(y==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3062b06fac50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclass_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_vec\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mrandom_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mvalid_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtrain_x_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# Specify the number of datapoints that should be sampled in each class to build training and validation set\n",
    "train_size = 160\n",
    "valid_size = 1997\n",
    "\n",
    "train_x = np.array([])\n",
    "train_y = np.array([])\n",
    "\n",
    "valid_x = np.array([])\n",
    "valid_y = np.array([])\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    class_index = np.where(label_vec == (i+1))[0]\n",
    "    random_index = np.random.choice(range(len(class_index)), size=train_size+valid_size, replace=False)\n",
    "    \n",
    "    train_x_class = class_index[random_index[:train_size]]\n",
    "    train_y_class = y[train_x_class]\n",
    "    train_x = np.append(train_x, train_x_class).astype(int)\n",
    "    train_y = np.append(train_y, train_y_class).astype(int)\n",
    "\n",
    "    valid_x_class = class_index[random_index[train_size:train_size+valid_size]]\n",
    "    valid_y_class = y[valid_x_class]\n",
    "    valid_x = np.append(valid_x, valid_x_class).astype(int)\n",
    "    valid_y = np.append(valid_y, valid_y_class).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Validation (Kiran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe that we tweaked parameters and which were found to be the optimal ones, comment on it...<br>\n",
    "Show the resulting accuracy that resulted when going trough the entire training set. For this, simply load a pickle or numpy array, with the results in it and comment on it<br>\n",
    "Add a .py funtion with which we could theoretically call to recompute the accuracy of the entire training set (in a \"if recompute is true\" conditioning). Add the function into main_pipeline.py. <br>\n",
    "(Optional) Also add clustering approach to compare, otherwise we will just mention it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4800/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
