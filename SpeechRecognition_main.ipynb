{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition using Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team members: Adrian LÃ¶wenstein, Kiran Bacsa, Manuel Vonlanthen<br>\n",
    "Date:         22.01.2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will describe in detail the problem we studied during the final project of the course \"Network Tour of Data Science\". We wanted to do speech recognition using the Graph/Network theory learned during the course. We were inspired by the kaggle competition \"Tensor Flow Speech Recognition Challenge: Can you build an algorithm that understands simple speech commands\" put up by google. In said competition the goal was to classify 20 distinct words. Words that do not belong to any of the 20 classes should be classified as \"unknown\". For the kaggle competition the TensorFlow library had to be used. For this purpose Google provided a large training data set (64'727 audio files) with known labels and an even larger test (150'000+ audio files) with unknown labels for them to evaluate the built algorithms. We, however, decided to only work with the provided training data, because the data set is large enough to perform statistically valid model evaluation and it this we we weren't dependant on the kaggle competition.<br>\n",
    "<br>\n",
    "The provided data set consists of 64'727 .wave files of length 1s, sampled with a sampling rate of $16$ kHz. Each audio files contain one of 30 possible spoken words. The files were created using crowd-sourcing, which means that the conditioning of the audio signal is not equal for all audio files. This led to very different noise levels, amplitudes, etc. Also the same speaker might have recorded different audio files. The 20 core words which have to be classified correctly are:\n",
    "\n",
    "    - up, down\n",
    "    - zero, one, two, three, four, five ,six ,seven, eight, nine\n",
    "    - go, stop \n",
    "    - left, rigth\n",
    "    - no, yes\n",
    "    - off, on\n",
    "In addition to these 20 words, 10 other words were provided inside the training set to train the algorithm to classify words which it should not react to as \"unknown\". The following \"unknown\" words are contained in the training data:\n",
    "\n",
    "    - bed\n",
    "    - bird, cat, dog, mouse\n",
    "    - tree\n",
    "    - happy\n",
    "    - marvin, sheila\n",
    "    - wow\n",
    "<br>\n",
    "At this point we want to empphasize that we did not study the problem suggested for the kaggle competition, but a slightly simplified one. First of all we did not restrict ourselves to using TensorFlow, in fact we did not use it at all. However, we did restrict ourselves to use Graph theory as central part of our classification algorithm. Our goal was, using only the provided training set, to build a classifier which calssifies the above listed core words as accurate as possible. In addition, all other words (the 10 additional words) should be classified as \"unknown\". This means we wanted to build a \"word\"-classifier for 21 different classes using graph theory.<br>\n",
    "<br>\n",
    "Mathematically, we can define the task as follows. We split up our training data set into a training set $S_t$ of some size N (we will later comment on its size) and a validation set $S_v$ of size $V = 64000-N$, used to check how well the classifier works.\n",
    "Using $\\mathbf{x_n} \\in S_t$, which is some training audio file $\\mathbf{x_n} \\in \\mathbb{R}^D$, where $D = 1s\\cdot 16kHz = 16000$ is the number of samples per audio file, we can build our training data matrix $\\mathbf{X}^{\\mathbf{N\\times D}}$. Using $\\mathbf{X}$ we want to learn a function $f(\\mathbf{v_v}, \\mathbf{X}): \\mathbb{R}^{N+1\\times D} \\to \\{1,2,3,...,21\\}$, where $\\mathbf{v_v}\\in S_v$ is a validation audio file $\\mathbf{v_v}\\in\\mathbb{R}^D$, such that the resulting estimated label $\\mathbf{\\hat{y}} = f(\\mathbf{v_V}, \\mathbf{X})$ is equal to the correct label $\\mathbf{y} \\in \\{1,2,3,...,21\\}$ for as many validation samples as possible. Hence we use the accuracy measure defined as\n",
    "$$acc = \\frac{\\sum_{i=1}^{K}\\max[\\min[(|y_k-\\hat{y_k}|),1],0]}{K},$$\n",
    "where $K$ is the number of tested samples $v_k$. We want to remark that the model could also work with a subset $\\mathbb{v}\\subseteq S_v$, instead of a single validation file $v_v$. In this case we define the cardinality of said subset $|\\mathbb{v}|=K$ and the model would correspond to $f(\\mathbb{v}, \\mathbf{X}): \\mathbb{R}^{N+K\\times D} \\to \\{1,2,3,...,21\\}^K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy import sparse, stats, spatial\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "\n",
    "# Benchmarking\n",
    "import time\n",
    "\n",
    "# Cutting \n",
    "\n",
    "from cut_audio import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** If you set recompute to True this will reextract all featrues and re-classify all audio file, which will take several days, so do not do it. It is here for completeness so you can see how the steps were done during th project. We've already computed these steps and saved the results into pickle files. Our entire used data, as well as the pickle files can be found on \"Link\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recompute = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction (Adrian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the data set....<br>\n",
    "Describe the entire pipeline from audio file to feature vector for one audio dile...<br>\n",
    "Shortly mentione other Features that were tried...<br>\n",
    "Set up python function in which the features of the entire training set could be extracted and put it into a if recompute is true... <br>\n",
    "Load the pickle with all features in them,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Classification (Manuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I this section we describe the entire semi-supervised classification we used in detail. It is basically a step by step description\n",
    "of the semisup pipeline using only one test batch of 200 in a Graph of 5000 nodes. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Validation (Kiran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe that we tweaked parameters and which were found to be the optimal ones, comment on it...<br>\n",
    "Show the resulting accuracy that resulted when going trough the entire training set. For this, simply load a pickle or numpy array, with the results in it and comment on it<br>\n",
    "Add a .py funtion with which we could theoretically call to recompute the accuracy of the entire training set (in a \"if recompute is true\" conditioning). Add the function into main_pipeline.py. <br>\n",
    "(Optional) Also add clustering approach to compare, otherwise we will just mention it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
