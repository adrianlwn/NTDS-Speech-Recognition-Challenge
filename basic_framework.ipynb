{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Framework\n",
    "First attempt to create a graph and a clustering of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# Math\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy import sparse, stats, spatial\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the Data\n",
    "----\n",
    "Use `N` random samples for each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "train_audio_path = '../Project/data/train/audio'\n",
    "dirs = [f for f in os.listdir(train_audio_path) if isdir(join(train_audio_path, f))]\n",
    "dirs.sort()\n",
    "\n",
    "path = []\n",
    "word = []\n",
    "speaker = []\n",
    "iteration = []\n",
    "\n",
    "for direct in dirs:\n",
    "    if not direct.startswith('_'):\n",
    "        # Random selection of N files per folder \n",
    "        list_files = os.listdir(join(train_audio_path, direct))\n",
    "        wave_selected  = list(np.random.choice([ f for f in list_files if f.endswith('.wav')],N,replace=False))\n",
    "        \n",
    "        # Extraction of file informations for dataframe\n",
    "        word.extend(list(np.repeat(direct,N,axis=0)))\n",
    "        speaker.extend([wave_selected[f].split('.')[0].split('_')[0] for f in range(N) ])\n",
    "        iteration.extend([wave_selected[f].split('.')[0].split('_')[-1] for f in range(N) ])\n",
    "        path.extend([train_audio_path + '/' + direct + '/' + wave_selected[f] for f in range(N)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the dataframe of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_og = pd.DataFrame({('info','word',''): word,\n",
    "                            ('info','speaker',''): speaker,\n",
    "                            ('info','iteration',''): iteration,\n",
    "                            ('info','path',''): path})\n",
    "index_og = [('info','word',''),('info','speaker',''),('info','iteration','')]\n",
    "#features_og.set_index(index_og,inplace=True)\n",
    "features_og.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features Extraction\n",
    "----\n",
    "### 2.1 MFCC\n",
    "A classical but reliable set a features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MFCC = 20\n",
    "\n",
    "def compute_mfcc(filepath):\n",
    "    audio, sampling_rate = librosa.load(filepath, sr=None, mono=True)\n",
    "    return librosa.feature.mfcc(y=audio,sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stat_name= ['mean','std','skew','kurtosis','median']\n",
    "col_names = [('mfcc',stat_name[i],j) for i in range(len(stat_name))  for j in range(N_MFCC)]\n",
    "features_mfcc =pd.DataFrame(columns=pd.MultiIndex.from_tuples(col_names),index=features_og.index)\n",
    "# sorting the columns in order to improve index performances (see lexsort errors)\n",
    "features_mfcc.sort_index(axis=1,inplace=True,sort_remaining=True)\n",
    "\n",
    "# MFCC FEATURES :\n",
    "for w in tqdm(range(len(features_og)),total=len(features_og),unit='waves'):\n",
    "    mfcc = compute_mfcc(features_og[('info','path')].iloc[w])\n",
    "    features_mfcc.loc[w, ('mfcc', 'mean')] = np.mean(mfcc,axis=1)\n",
    "    features_mfcc.loc[w, ('mfcc', 'std')] = np.std(mfcc,axis=1)\n",
    "    features_mfcc.loc[w, ('mfcc', 'skew')] = scipy.stats.skew(mfcc,axis=1)\n",
    "    features_mfcc.loc[w, ('mfcc', 'kurtosis')] = scipy.stats.kurtosis(mfcc,axis=1)\n",
    "    features_mfcc.loc[w, ('mfcc', 'median')] = np.median(mfcc,axis=1)\n",
    "\n",
    "features_og = features_og.merge(features_mfcc,left_index=True,right_index=True)\n",
    "features_og.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset features into a pickle to avoid to redo the computation on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_og.to_pickle('./Features Data/trainingFeatures.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the pickle containing the previously saved features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_og = pd.read_pickle('./Features Data/trainingFeatures.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features\n",
    "features = pd.DataFrame(features_og)\n",
    "features -= features.mean(axis=0)\n",
    "features /= features.std(axis=0)\n",
    "\n",
    "distances = spatial.distance.squareform(spatial.distance.pdist(features,'cosine'))\n",
    "\n",
    "n=distances.shape[0]\n",
    "kernel_width = distances.mean()\n",
    "weights = np.exp(np.divide(-np.square(distances),kernel_width**2))\n",
    "np.fill_diagonal(weights,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(2, 2, figsize=(17, 8))\n",
    "def plot(weights, axes):\n",
    "    axes[0].spy(weights)\n",
    "    axes[1].hist(weights[weights > 0].reshape(-1), bins=50);\n",
    "plot(weights, axes[:, 0])\n",
    "\n",
    "NEIGHBORS = 30\n",
    "\n",
    "for i in range(weights.shape[0]):\n",
    "    idx = weights[i,:].argsort()[:-NEIGHBORS]\n",
    "    weights[i,idx] = 0\n",
    "    weights[idx,i] = 0\n",
    "\n",
    "plot(weights, axes[:, 1])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.sum(weights,axis=0)\n",
    "laplacian = np.diag(degrees**-0.5) @ (np.diag(degrees) - weights) @ np.diag(degrees**-0.5)\n",
    "laplacian = sparse.csr_matrix(laplacian)\n",
    "plt.matshow(laplacian.todense());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = sparse.linalg.eigsh(A=laplacian,k=10,which='SM')\n",
    "\n",
    "plt.plot(eigenvalues, '.-', markersize=15);\n",
    "\n",
    "x = eigenvectors[:,1]\n",
    "y = eigenvectors[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(5, 5, figsize=(17, 8))\n",
    "for i in range(1,6):\n",
    "    for j in range(1,6):\n",
    "        x = eigenvectors[:,i]\n",
    "        y = eigenvectors[:,j]\n",
    "        labels = np.sign(x)\n",
    "        axes[i-1,j-1].scatter(x, y, c=labels, cmap='RdBu', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ntds]",
   "language": "python",
   "name": "conda-env-ntds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
